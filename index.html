<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Product Recognition</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            height: 100vh;
            background-color: #f0f0f0;
            font-family: Arial, sans-serif;
        }
        #video, #canvas {
            width: 100%;
            max-width: 640px;
            height: auto;
            border: 2px solid #333;
        }
        #output {
            margin-top: 20px;
            font-size: 18px;
            text-align: center;
        }
        #error {
            color: red;
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <video id="video" autoplay playsinline></video>
    <canvas id="canvas" style="display: none;"></canvas>
    <div id="output">Loading model...</div>
    <div id="error"></div>

    <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
    <script>
        // Replace with your Teachable Machine model URL
        const modelURL = 'https://your-github-repo/path/to/model.json';
        const metadataURL = 'https://your-github-repo/path/to/metadata.json';

        let model, video, canvas, ctx, output, errorDiv;

        async function init() {
            video = document.getElementById('video');
            canvas = document.getElementById('canvas');
            ctx = canvas.getContext('2d');
            output = document.getElementById('output');
            errorDiv = document.getElementById('error');

            // Load the Teachable Machine model
            try {
                model = await tmImage.load(modelURL, metadataURL);
                output.textContent = 'Model loaded successfully!';
            } catch (error) {
                errorDiv.textContent = 'Error loading model: ' + error.message;
                return;
            }

            // Set up the video stream with rear-facing camera
            try {
                const stream = await navigator.mediaDevices.getUserMedia({
                    video: {
                        facingMode: 'environment' // Use rear-facing camera
                    }
                });
                video.srcObject = stream;
                video.onloadedmetadata = () => {
                    video.play();
                    canvas.width = video.videoWidth;
                    canvas.height = video.videoHeight;
                    predict();
                };
            } catch (error) {
                errorDiv.textContent = 'Error accessing camera: ' + error.message;
            }
        }

        async function predict() {
            // Draw the video frame to the canvas
            ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

            // Make a prediction
            const prediction = await model.predict(canvas);
            let maxProb = 0;
            let label = '';

            // Find the prediction with the highest probability
            for (let i = 0; i < prediction.length; i++) {
                if (prediction[i].probability > maxProb) {
                    maxProb = prediction[i].probability;
                    label = prediction[i].className;
                }
            }

            // Update the output
            output.textContent = Prediction: ${label} (${(maxProb * 100).toFixed(2)}%);

            // Continue predicting
            requestAnimationFrame(predict);
        }

        // Start the application
        window.onload = init;
    </script>
</body>
</html>
